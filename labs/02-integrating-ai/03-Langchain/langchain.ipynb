{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Langchain\n",
    "\n",
    "In this lab, we will introduce [Langchain](https://python.langchain.com/docs/get_started/introduction), a framework for developing applications powered by language models.\n",
    "\n",
    "Langchain supports Python and Javascript / Typescript. For this lab, we will use Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by importing the `AzureOpenAI` specific components from the `langchain` package, including models and schemas for interacting with the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import AzureOpenAI\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with all the other labs, we'll need to provide our API key and endpoint details, so we'll load them from our `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Azure OpenAI Endpoint: https://aoai-intelligent-apps-swe02.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "if load_dotenv():\n",
    "    print(\"Found Azure OpenAI Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "else: \n",
    "    print(\"No file .env found\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll configure Langchain by providing the Azure OpenAI deployment name. Langchain will automatically retrieve details for the Azure OpenAI endpoint and version from the environment variables we've set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of Azure OpenAI\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a prompt to Azure OpenAI using Langchain\n",
    "\n",
    "We're now ready to send a request to Azure OpenAI. To do this, we invoke the `llm` instance we created above and pass in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the age of the current President of the United States, you can follow these steps:\n",
      "\n",
      "1. Identify the current President: As of my knowledge cutoff in October 2021, the President of the United States is Joseph R. Biden Jr. However, please note that this information may change in the future.\n",
      "\n",
      "2. Find the date of birth: Research the date of birth of Joseph R. Biden Jr. You can do this by searching online or referring to reputable sources such as official biographies or news articles.\n",
      "\n",
      "3. Calculate the current age: Subtract the year of birth from the current year to determine the age of the President. For example, if the President was born in 1942 and the current year is 2021, you would subtract 1942 from 2021 to find the age.\n",
      "\n",
      "4. Consider the date of the calculation: Keep in mind that the President's age may vary depending on when you are making the calculation. As time passes, the President's age will increase.\n",
      "\n",
      "It's worth noting that the steps provided above are applicable to determining the age of Joseph R. Biden Jr. as of October 2021. If you are referring to a future or past President, you would need to substitute the current President's name and relevant details accordingly.\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt we want the AI to respond to - the message the Human user is asking\n",
    "msg = HumanMessage(content=\"Explain step by step. How old is the president of USA?\")\n",
    "\n",
    "# Call the API\n",
    "r = llm.invoke([msg])\n",
    "\n",
    "# Print the response\n",
    "print(r.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a prompt to Azure OpenAI using Langchain Chaining\n",
    "\n",
    "Now that we have seen Langchain in action, let's take a quick peek at chaining and adding variables to our prompt. To do this we will add `LLMChain` to the `llm` instance created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the OpenAI API, we still had to pass the prompt in using the `Completion.create()` method. With Langchain, we can create a `PromptTemplate`. This way, we can define our prompt up front and leave placeholders for values that will be set later on. The placeholder could be values that are passed from an end user or application via an API. We don't know what they at this point.\n",
    "\n",
    "In the below example, the `{input}` in curly brackets is the placeholder value that will be populated later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template with variables, note the curly braces\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    template=\"What interesting things can I make with a {input}?\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define a chain. In this case, the chain has two components. One component is the prompt template. The other is the object that represents our AI model (`llm`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we initiate the chain. You can see that we pass in a value for the `input` placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are numerous interesting projects you can create with a Raspberry Pi. Here are a few examples:\n",
      "\n",
      "1. Retro Gaming Console: Build a classic gaming console using software like RetroPie, allowing you to play games from various retro gaming systems.\n",
      "\n",
      "2. Home Automation System: Control and automate your home appliances, lights, and security systems using the Raspberry Pi along with sensors and relays.\n",
      "\n",
      "3. Media Center: Transform your Raspberry Pi into a media center using Kodi, enabling you to stream movies, TV shows, and music.\n",
      "\n",
      "4. Weather Station: Create a weather monitoring system by connecting sensors to your Raspberry Pi and displaying real-time weather data.\n",
      "\n",
      "5. Pi-powered Robot: Build a small robot using a Raspberry Pi, motors, and sensors, and program it to perform tasks autonomously.\n",
      "\n",
      "6. Smart Mirror: Construct a mirror that displays information such as time, weather, calendar events, and news headlines using a Raspberry Pi and a two-way mirror.\n",
      "\n",
      "7. Network Monitoring Tool: Develop a network monitoring system to track and analyze network traffic, monitor devices, and identify potential vulnerabilities.\n",
      "\n",
      "8. Portable Pi Laptop: Construct a portable Raspberry Pi laptop by integrating an LCD screen, keyboard, and battery pack for on-the-go computing.\n",
      "\n",
      "9. Home Security System: Create a DIY security system with motion sensors, cameras, and a Raspberry Pi to monitor your home and send alerts.\n",
      "\n",
      "10. Pi-powered Arcade Cabinet: Design and build your own retro arcade cabinet using a Raspberry Pi, joystick, buttons, and a display, allowing you to play classic arcade games.\n",
      "\n",
      "These are just a few examples, and the possibilities are nearly limitless. The Raspberry Pi's versatility and affordability make it an excellent platform for exploring various projects and learning about electronics, programming, and automation.\n"
     ]
    }
   ],
   "source": [
    "# Run the chain only specifying the input variable.\n",
    "response = chain.invoke({\"input\": \"raspberry pi\"})\n",
    "\n",
    "# As we are using a single input variable, you could also run the string like this:\n",
    "# response = chain.run(\"raspberry pi\")\n",
    "\n",
    "print(response['text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Langchain is an example of an AI orchestrator. It provides an alternative method to the raw API or using an SDK package to access the AI models, but on top of that can provide additional integrations, deal with issues related to rate limiting of the API and provide an abstraction layer over potentially complex operations. We'll get into those more complex use cases in later labs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up Next\n",
    "\n",
    "In the next lab, we'll look at another AI Orchestrator - Semantic Kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Section\n",
    "\n",
    "📣 [Semantic Kernel](../04-SemanticKernel/semantickernel.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
